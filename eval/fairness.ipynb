{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Load models and data\n",
    "with open('models/good_model.pkl', 'rb') as f:\n",
    "    good_model = pickle.load(f)\n",
    "with open('models/bad_model.pkl', 'rb') as f:\n",
    "    bad_model = pickle.load(f)\n",
    "with open('data/test_data.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_test = test_data['X_test']\n",
    "y_test = test_data['y_test']\n",
    "\n",
    "def test_demographic_fairness(model, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    # Single attribute tests\n",
    "    protected_attrs = {\n",
    "        'age': ('persoon_leeftijd_bij_onderzoek', lambda x: pd.qcut(x, 4, labels=['youngest', 'young', 'middle', 'oldest'])),\n",
    "        'gender': ('persoon_geslacht_vrouw', lambda x: x.map({0: 'male', 1: 'female'})),\n",
    "        'neighborhood': ('wijk_', lambda x: x.idxmax(axis=1))\n",
    "    }\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    for attr_name, (attr_col, transform_fn) in protected_attrs.items():\n",
    "        if attr_name == 'neighborhood':\n",
    "            cols = [c for c in X.columns if attr_col in c]\n",
    "            groups = transform_fn(X[cols])\n",
    "        else:\n",
    "            groups = transform_fn(X[attr_col])\n",
    "            \n",
    "        approval_rates = groups.map(lambda g: np.mean(y_pred[groups == g] == 1))\n",
    "        results[attr_name] = {\n",
    "            'disparity': max(approval_rates) - min(approval_rates),\n",
    "            'rates': approval_rates.to_dict()\n",
    "        }\n",
    "    \n",
    "    # Intersectional test (age + gender)\n",
    "    age_groups = protected_attrs['age'][1](X[protected_attrs['age'][0]])\n",
    "    gender_groups = protected_attrs['gender'][1](X[protected_attrs['gender'][0]])\n",
    "    intersect_groups = age_groups + '_' + gender_groups\n",
    "    \n",
    "    intersect_rates = intersect_groups.map(lambda g: np.mean(y_pred[intersect_groups == g] == 1))\n",
    "    results['intersectional'] = {\n",
    "        'disparity': max(intersect_rates) - min(intersect_rates),\n",
    "        'rates': intersect_rates.to_dict()\n",
    "    }\n",
    "    \n",
    "    # Individual fairness\n",
    "    preds = model.predict_proba(X)\n",
    "    distances = pdist(X)\n",
    "    pred_distances = pdist(preds)\n",
    "    results['individual'] = {\n",
    "        'fairness_score': np.corrcoef(distances, pred_distances)[0,1]\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate models\n",
    "models = {'Good': good_model, 'Bad': bad_model}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Model Fairness Results:\")\n",
    "    results = test_demographic_fairness(model, X_test, y_test)\n",
    "    \n",
    "    for test_name, metrics in results.items():\n",
    "        print(f\"\\n{test_name.title()} Test:\")\n",
    "        if 'disparity' in metrics:\n",
    "            print(f\"Max disparity: {metrics['disparity']:.2%}\")\n",
    "            print(\"Approval rates:\")\n",
    "            for group, rate in metrics['rates'].items():\n",
    "                print(f\"- {group}: {rate:.2%}\")\n",
    "        else:\n",
    "            print(f\"Fairness score: {metrics['fairness_score']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
