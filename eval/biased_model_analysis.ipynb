{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:29:30.832042Z",
     "start_time": "2024-12-10T15:29:29.153480Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model and data\n",
    "with open('../models/biased_model.pkl', 'rb') as f:\n",
    "   model = pickle.load(f)\n",
    "   \n",
    "df = pd.read_csv('../data/investigation_train_large_checked.csv')\n",
    "features = [col for col in df.columns if col not in ['checked', 'ja', 'nee']]\n",
    "X = df[features]\n",
    "X_test = df[features]\n",
    "feature_names = X.columns.tolist()\n",
    "y_test = df['checked']\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taouf/Library/Caches/JetBrains/PyCharm2024.2/demo/PyCharmLearningProject/venv/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/taouf/Library/Caches/JetBrains/PyCharm2024.2/demo/PyCharmLearningProject/venv/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/taouf/Library/Caches/JetBrains/PyCharm2024.2/demo/PyCharmLearningProject/venv/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/taouf/Library/Caches/JetBrains/PyCharm2024.2/demo/PyCharmLearningProject/venv/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/taouf/Library/Caches/JetBrains/PyCharm2024.2/demo/PyCharmLearningProject/venv/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:43:01.900182Z",
     "start_time": "2024-12-10T15:43:01.880923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feature_importances(pipeline_or_model):\n",
    "    \"\"\"Helper function to get feature importances whether using a pipeline or direct model\"\"\"\n",
    "    if hasattr(pipeline_or_model, 'named_steps'):  # If it's a pipeline\n",
    "        # Get the last step (usually the model)\n",
    "        model = pipeline_or_model.named_steps['classifier']\n",
    "        return model.feature_importances_\n",
    "    else:  # If it's just the model\n",
    "        return pipeline_or_model.feature_importances_\n",
    "\n",
    "def test_location_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Test 1: Analyzes how much the model relies on location-related features\n",
    "    \"\"\"\n",
    "    importances = get_feature_importances(model)\n",
    "    \n",
    "    # Calculate importance by location feature type\n",
    "    location_importance = {\n",
    "        'neighborhood': sum(importances[6:11]),\n",
    "        'district': sum(importances[13:22]),\n",
    "        'rotterdam': sum(importances[i] for i in [11,12])\n",
    "    }\n",
    "    \n",
    "    # Total location importance\n",
    "    total_location_importance = sum(location_importance.values())\n",
    "    total_model_importance = sum(importances)\n",
    "    \n",
    "    return {\n",
    "        'location_importance_ratio': total_location_importance / total_model_importance,\n",
    "        'location_breakdown': location_importance,\n",
    "        'interpretation': f\"Location features account for {(total_location_importance/total_model_importance)*100:.1f}% of model's decision making\"\n",
    "    }\n",
    "\n",
    "def test_age_discrimination(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Test 2: Checks if model discriminates based on age\n",
    "    \"\"\"\n",
    "    # Create age groups\n",
    "    age_values = X_test.iloc[:, 0]  # Age is first column\n",
    "    age_groups = pd.qcut(age_values, q=4, labels=['youngest', 'young', 'middle', 'oldest'])\n",
    "    \n",
    "    group_metrics = {}\n",
    "    for group in age_groups.unique():\n",
    "        mask = age_groups == group\n",
    "        group_preds = model.predict(X_test[mask])\n",
    "        group_true = y_test[mask]\n",
    "        \n",
    "        group_metrics[group] = {\n",
    "            'approval_rate': np.mean(group_preds == 1),\n",
    "            'accuracy': accuracy_score(group_true, group_preds)\n",
    "        }\n",
    "    \n",
    "    # Calculate disparities\n",
    "    approval_rates = [metrics['approval_rate'] for metrics in group_metrics.values()]\n",
    "    max_disparity = max(approval_rates) - min(approval_rates)\n",
    "    \n",
    "    return {\n",
    "        'age_group_metrics': group_metrics,\n",
    "        'max_approval_disparity': max_disparity,\n",
    "        'interpretation': f\"Maximum approval rate disparity between age groups: {max_disparity:.2%}\"\n",
    "    }\n",
    "\n",
    "def test_neighborhood_bias(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Test 3: Checks for bias in different neighborhoods\n",
    "    \"\"\"\n",
    "    # Get neighborhood features (columns 6-10)\n",
    "    neighborhood_features = X_test.iloc[:, 6:11]\n",
    "    \n",
    "    # Find which neighborhood each sample belongs to (one-hot encoded)\n",
    "    neighborhoods = neighborhood_features.idxmax(axis=1)\n",
    "    \n",
    "    neighborhood_metrics = {}\n",
    "    for neighborhood in neighborhood_features.columns:\n",
    "        mask = neighborhoods == neighborhood\n",
    "        if sum(mask) > 0:  # If we have samples for this neighborhood\n",
    "            n_preds = model.predict(X_test[mask])\n",
    "            n_true = y_test[mask]\n",
    "            \n",
    "            neighborhood_metrics[neighborhood] = {\n",
    "                'approval_rate': np.mean(n_preds == 1),\n",
    "                'accuracy': accuracy_score(n_true, n_preds),\n",
    "                'sample_size': sum(mask)\n",
    "            }\n",
    "    \n",
    "    # Calculate disparities\n",
    "    approval_rates = [metrics['approval_rate'] for metrics in neighborhood_metrics.values()]\n",
    "    max_disparity = max(approval_rates) - min(approval_rates)\n",
    "    \n",
    "    return {\n",
    "        'neighborhood_metrics': neighborhood_metrics,\n",
    "        'max_approval_disparity': max_disparity,\n",
    "        'interpretation': f\"Maximum approval rate disparity between neighborhoods: {max_disparity:.2%}\"\n",
    "    }\n",
    "\n",
    "\n",
    "def test_model_performance(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Test 4: Evaluates overall model performance using multiple metrics\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, predictions),\n",
    "        'precision': precision_score(y_test, predictions),\n",
    "        'recall': recall_score(y_test, predictions),\n",
    "        'f1_score': f1_score(y_test, predictions)\n",
    "    }\n",
    "    \n",
    "    # Get confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    total_predictions = len(predictions)\n",
    "    positive_rate = np.mean(predictions == 1)\n",
    "    \n",
    "    return {\n",
    "        'standard_metrics': metrics,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'total_samples': total_predictions,\n",
    "        'positive_prediction_rate': positive_rate,\n",
    "        'interpretation': (\n",
    "            f\"Model Performance:\\n\"\n",
    "            f\"Accuracy: {metrics['accuracy']:.2%}\\n\"\n",
    "            f\"Precision: {metrics['precision']:.2%}\\n\"\n",
    "            f\"Recall: {metrics['recall']:.2%}\\n\"\n",
    "            f\"F1 Score: {metrics['f1_score']:.2%}\\n\"\n",
    "            f\"Overall positive prediction rate: {positive_rate:.2%}\"\n",
    "        )\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:43:06.748977Z",
     "start_time": "2024-12-10T15:43:02.510991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run tests\n",
    "location_results = test_location_importance(model, feature_names)\n",
    "age_results = test_age_discrimination(model, X_test, y_test)\n",
    "neighborhood_results = test_neighborhood_bias(model, X_test, y_test)\n",
    "distribution_results = test_model_performance(model, X_test, y_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Test 1 - Location Importance:\")\n",
    "print(location_results['interpretation'])\n",
    "print(\"\\nBreakdown:\", location_results['location_breakdown'])\n",
    "\n",
    "print(\"\\nTest 2 - Age Discrimination:\")\n",
    "print(age_results['interpretation'])\n",
    "print(\"Age group metrics:\", age_results['age_group_metrics'])\n",
    "\n",
    "print(\"\\nTest 3 - Neighborhood Bias:\")\n",
    "print(neighborhood_results['interpretation'])\n",
    "print(\"Neighborhood metrics:\", neighborhood_results['neighborhood_metrics'])\n",
    "\n",
    "print(\"\\nTest 4 - Feature Bias Distribution:\")\n",
    "print(distribution_results['interpretation'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 - Location Importance:\n",
      "Location features account for 0.7% of model's decision making\n",
      "\n",
      "Breakdown: {'neighborhood': np.float64(0.0007548429228768742), 'district': np.float64(0.0062959077739670015), 'rotterdam': np.float64(0.00017616990137220284)}\n",
      "\n",
      "Test 2 - Age Discrimination:\n",
      "Maximum approval rate disparity between age groups: 6.67%\n",
      "Age group metrics: {'youngest': {'approval_rate': np.float64(0.12839304660083245), 'accuracy': 1.0}, 'middle': {'approval_rate': np.float64(0.1682614006514658), 'accuracy': 1.0}, 'oldest': {'approval_rate': np.float64(0.19511927611735674), 'accuracy': 1.0}, 'young': {'approval_rate': np.float64(0.1547387527550888), 'accuracy': 1.0}}\n",
      "\n",
      "Test 3 - Neighborhood Bias:\n",
      "Maximum approval rate disparity between neighborhoods: 3.24%\n",
      "Neighborhood metrics: {'adres_recentste_buurt_groot_ijsselmonde': {'approval_rate': np.float64(0.1474564761081615), 'accuracy': 1.0, 'sample_size': 64792}, 'adres_recentste_buurt_nieuwe_westen': {'approval_rate': np.float64(0.15274463007159905), 'accuracy': 1.0, 'sample_size': 419}, 'adres_recentste_buurt_other': {'approval_rate': np.float64(0.15268629226110572), 'accuracy': 1.0, 'sample_size': 64066}, 'adres_recentste_buurt_oude_noorden': {'approval_rate': np.float64(0.12030075187969924), 'accuracy': 1.0, 'sample_size': 133}, 'adres_recentste_buurt_vreewijk': {'approval_rate': np.float64(0.14915254237288136), 'accuracy': 1.0, 'sample_size': 590}}\n",
      "\n",
      "Test 4 - Feature Bias Distribution:\n",
      "Model Performance:\n",
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 Score: 100.00%\n",
      "Overall positive prediction rate: 15.00%\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
